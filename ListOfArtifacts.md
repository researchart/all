# List of known artifact types

Note that some artifacts are executable (e.g. scripts) and some are not (e.g. tutorials). For a discussion on why we might want to divide our work in to the following areas, see the [SE research reuse manifesto](SEresearchReuseManifesto.md).

The following list is sorted by artifact size, from  _smaller_ to _bigger_. 
Note also that research artifacts can be _smaller_ than a research paper (i.e. one paper can contain many artifacts) or _bigger_ (e.g. a paper might use soem scripts or data)

If your artifact is not included in the above, then write an issue in this repo to propose a new artifact type.

1. _Motivational statements_   or reports or challenge statements or lists of open issues that prompt an analysis; 
1. _Hypotheses_,  about expected effects in some area;
1. _Checklists _used to design the analysis (see also, the [Checklist Manifesto](http://atulgawande.com/book/the-checklist-manifesto/);
1. _Bibliographies_, some of which might be annotated;
1. _Study instruments _ such as surveys interview scripts, etc;
1. _Statistical tests_ used to analyze results;
1. _Commentary_ on scripts used in the analysis;
1. Examples of particularly _informative visualizations_ (e.g. Sparklines http://www.edwardtufte.com/bboard/q-and-a-fetch-msg?msg_id=0001OR )
1. _Baseline results_ against which new work can be compared;
1. _Sampling procedures_ e.g. ``how did you choose the projects you studied?'';
1. _Patterns_ describing  best practices for performing this kind of analysis;
1. _Anti-patterns_   describing cautionary tales of ``gotchas'' to avoid when doing this kind of work;
1. _Negative results_  that are anti-patterns, backed up by empirical results;
1. _Tutorial materials_: Guides to help  newcomers become proficient in the area. Some of these tutorial materials  may be generated by the researcher and others may be collected from other sources.
1. _New results _  that offer guidance on how to best handle future problems.
1. _Future work:_  From the results, there many be speculations about open issues of future issues that might become the  motivation  for the next round of research.
1. The _actual text_   of an author's papers;
1. Any  _data_ used in an analysis
    + Either  _raw_ from a project;
    + Or some _redived_ product.
   Note that some data is too large to fit into the standard on-line freely available repos (e.g. Github only allows 1GB reps). For such data, we suggest using some file `XXX.goto`; each line of which is one url where the releated data can be collected. 
1. _Scripts_  used to perform the analysis (the main analysis or the subsequent statistical tests or visualizations; e.g.    the  [Python Sparklines generator](https://pypi.python.org/pypi/pysparklines)). Scripts can also implement some of the patterns
  identified by the paper.
1. _Executable  models_ that can generate exemplar data;  or which offer an executable form of current hypotheses;
1. _Delivery tools_ to let novices automatically rerun the analysis; e.g.
    + Config management files that can
       + build the system/ paper from raw material and/or
       + update the relevant files using some package manager
    +  Virtual machines containing all the above scripts, data, etc, pre-configured such that a newcomer can automatically run the old analysis.
